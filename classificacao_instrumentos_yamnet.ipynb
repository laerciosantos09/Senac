{
 "cells": [
  {
   "cell_type": "code",
   "source": "# \ud83d\udce6 Instala\u00e7\u00e3o de bibliotecas\n!pip install kaggle tensorflow tensorflow_hub librosa matplotlib seaborn tqdm",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \ud83d\udcc1 Configura\u00e7\u00e3o de diret\u00f3rios\nimport os\nos.makedirs('/content/kaggle', exist_ok=True)\nos.makedirs('/root/.kaggle', exist_ok=True)\n\n# \ud83d\udd11 Baixando kaggle.json do Google Drive\nimport requests\nfile_id = \"1drlyKgvfvFaE69SzowRjcF5KK14jaroQ\"\nurl = f\"https://drive.google.com/uc?export=download&id={file_id}\"\ndest_path = \"/content/kaggle/kaggle.json\"\nresponse = requests.get(url)\nwith open(dest_path, \"wb\") as f:\n    f.write(response.content)\n!cp \"{dest_path}\" \"/root/.kaggle\"\n!chmod 600 /root/.kaggle/kaggle.json",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \ud83d\udcc5 Download e descompacta\u00e7\u00e3o do dataset\nDATA_DIR = '/content/musical'\nDATASET_SLUG = 'soumendraprasad/musical-instruments-sound-dataset'\nZIP_FILE = os.path.join(DATA_DIR, 'musical-instruments-sound-dataset.zip')\nos.makedirs(DATA_DIR, exist_ok=True)\n!kaggle datasets download -d {DATASET_SLUG} -p {DATA_DIR}\n!unzip -q {ZIP_FILE} -d {DATA_DIR}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \ud83d\udd0d An\u00e1lise Explorat\u00f3ria\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import wavfile\nimport librosa\nimport librosa.display\n\ndf = pd.read_csv(f\"{DATA_DIR}/Metadata_Train.csv\")\ndf2 = pd.read_csv(f\"{DATA_DIR}/Metadata_Test.csv\")\n\nprint(df['Class'].value_counts())\nplt.figure(figsize=(22,10))\nsns.countplot(df['Class'])\nplt.xticks(rotation=0)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df.set_index('FileName', inplace=True)\nfor f in df.index:\n    rate, signal = wavfile.read(f\"{DATA_DIR}/Train_submission/Train_submission/\" + f)\n    df.at[f, 'length'] = signal.shape[0]/rate\n\nclasses = list(np.unique(df.Class))\nclass_dist = df.groupby(['Class'])['length'].mean()\n\nfig, ax = plt.subplots()\nax.set_title('Distribui\u00e7\u00e3o por Classe', y=1.08)\nax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%', shadow=False, startangle=90)\nax.axis('equal')\nplt.show()\ndf.reset_index(inplace=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def calc_fft(y, sr):\n    n = len(y)\n    freq = np.fft.rfftfreq(n, d=1/sr)\n    Y = abs(np.fft.rfft(y)/n)\n    return (Y, freq)\n\ndef Envelope(y, rate, threshold):\n    y = pd.Series(y).apply(np.abs)\n    y_mean = y.rolling(window=int(rate/4), min_periods=1, center=True).mean()\n    return y_mean > threshold\n\nsignals = {}\nfft = {}\nfnames = []\n\nfor c in classes:\n    wav_file = df[df.Class == c].iloc[0, 0]\n    fnames.append(f\"{DATA_DIR}/Train_submission/Train_submission/\" + wav_file)\n    signal, rate = librosa.load(fnames[-1], sr=44100)\n    mask = Envelope(signal, rate, 0.0005)\n    signal = signal[mask]\n    signals[c] = signal\n    fft[c] = calc_fft(signal, rate)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_signals(signals):\n    fig, axes = plt.subplots(1, 4, figsize=(20,5))\n    fig.suptitle('Sinais Temporais', size=16)\n    for i, (label, sig) in enumerate(signals.items()):\n        axes[i].set_title(label)\n        axes[i].plot(sig)\n        axes[i].axis('off')\nplot_signals(signals)\nplt.show()\n\ndef plot_fft(fft):\n    fig, axes = plt.subplots(1, 4, figsize=(20,5))\n    fig.suptitle('Transformadas de Fourier', size=16)\n    for i, (label, data) in enumerate(fft.items()):\n        Y, freq = data\n        axes[i].set_title(label)\n        axes[i].plot(freq, Y)\n        axes[i].axis('off')\nplot_fft(fft)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "hop_length = 512\nfig, ax = plt.subplots(1, 4, figsize=(16, 9))\nfig.suptitle('Espectrogramas Mel', fontsize=16)\n\nfor i, fname in enumerate(fnames):\n    y_data, sr_data = librosa.load(fname, sr=25000)\n    S = librosa.feature.melspectrogram(y_data, sr=25000)\n    S_db = librosa.amplitude_to_db(S, ref=np.max)\n    librosa.display.specshow(S_db, sr=25000, hop_length=hop_length, x_axis='time', y_axis='log', cmap='rainbow', ax=ax[i])\n    ax[i].set_title(classes[i], fontsize=13)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import tensorflow_hub as hub\nyamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n\ndef preprocess_audio(file_path):\n    waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n    waveform = waveform / np.max(np.abs(waveform))\n    return waveform\n\ndef extract_embeddings(waveform):\n    scores, embeddings, spectrogram = yamnet_model(waveform)\n    return embeddings.numpy().mean(axis=0)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\n\nX = []\ny = []\n\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    try:\n        waveform = preprocess_audio(f\"{DATA_DIR}/Train_submission/Train_submission/\" + row['FileName'])\n        embedding = extract_embeddings(waveform)\n        X.append(embedding)\n        y.append(row['Class'])\n    except Exception as e:\n        print(f\"Erro no arquivo {row['FileName']}: {e}\")\n\nX = np.array(X)\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\ny_cat = to_categorical(y_encoded)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\nmodel =
